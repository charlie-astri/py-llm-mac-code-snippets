
# llm-config setting for deepseek model
# reference URL: https://platform.deepseek.com/
llm_config = {
    "config_list": [{
        "model": "deepseek-chat",
        "api_key": "you api key on deepseek platform",
        "base_url": "https://api.deepseek.com",
        "temperature": 0
    }]
}